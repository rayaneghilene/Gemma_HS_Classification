# Gemma7B Binary Hate Speech Classification

<div style="text-align:center" width:100px;">
    <img src="https://github.com/rayaneghilene/Gemma_HS_Classification/assets/100053511/3aff4c33-9245-4ef3-9b76-0dc557f6928a" alt="Gemma" >
</div>

## Model

Gemma is a family of lightweight, state-of-the-art open models developed by Google. These models are built from the same research and technology used to create the Gemini models. Here are the key details about Gemma 7B:

* **Model Size:** Gemma 7B refers to the “7 billion parameter model.”
* **Purpose**: It is designed for efficient deployment and development on both GPUs and TPUs.
* **Variants:** Each size (2B and 7B) is released with pre-trained and instruction-tuned variants.
* **Responsible AI:** Gemma is built for responsible AI development, adhering to Google’s AI Principles.
* **Performance:** Gemma models achieve best-in-class performance for their sizes compared to other open models.
* **Usage:** Gemma models can run directly on developer laptops, workstations, or Google Cloud.


Gemma is provided under and subject to the [Gemma Terms of Use](https://ai.google.dev/gemma/terms) found at ai.google.dev/gemma/terms.



## Test results
'hate': 1, 'nothate':0

![image](https://github.com/rayaneghilene/Gemma_HS_Classification/assets/100053511/63ef94ba-c573-4ed9-9d1c-2e2b015d8e5a)



## Dataset

**Dynamically-Generated-Hate-Speech-Dataset**

```ruby
    @misc{vidgen2021learning,
          title={Learning from the Worst: Dynamically Generated Datasets to Improve Online Hate Detection}, 
          author={Bertie Vidgen and Tristan Thrush and Zeerak Waseem and Douwe Kiela},
          year={2021},
          eprint={2012.15761},
          archivePrefix={arXiv},
          primaryClass={cs.CL}
    }
```


## Contact
If you have any questions or would like to discuss my work further, please don't hesitate to contact me at rayane.ghilene@ensea.fr.
